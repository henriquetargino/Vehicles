{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bibliotecas\n",
    "import pandas as pd\n",
    "import time\n",
    "# funções \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# modelos\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "legenda: treino, teste, erro, tempo<br><br>\n",
    "n_estimators=11, max_depth=27 -> 0.9557926155884157 0.8334794802644814 3931.966016272742 8.193240880966187<br> <br>\n",
    "n_estimators=100, max_depth=27 -> 0.9650129200912126 0.8408169218841756 3873.6263369273256 79.8025176525116<br>\n",
    "# Linear Regression\n",
    "legenda: treino, teste, erro<br><br>\n",
    "fit_intercept=True, n_jobs=-1 -> 0.6463556388680558 0.5734454636073181 6866.667619648236<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula usada para encontrar os melhores hiperparâmetros da Random Forest\n",
    "\n",
    "```best_error = float('inf')\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "\n",
    "for est in range(10, 101, 5):\n",
    "    for depth in range(20, 31):\n",
    "        model = RandomForestRegressor(random_state=1506, n_estimators=est, max_depth=depth)\n",
    "        model.fit(features_train, target_train)\n",
    "        predictions_test = model.predict(features_test)\n",
    "        error = mean_squared_error(target_test, predictions_test)**0.5\n",
    "        print(f\"Validação de REQM para n_estimators={est}, depth={depth} é {error}\")\n",
    "        if error < best_error:\n",
    "            best_error = error\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "\n",
    "print(f\"Melhor REQM de teste: {best_error} com n_estimators={best_est} e max_depth={best_depth}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando dataset\n",
    "car_data = pd.read_csv('datasets/car_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retirando colunas que não serão utilizadas\n",
    "car_data = car_data.drop(['date_posted', 'days_listed', 'year_posted', 'car_age'] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformando a coluna condition em numérica colocando \"pesos\" para cada condição\n",
    "condition_mapping = {\n",
    "    \"new\": 5,\n",
    "    \"like new\": 4,\n",
    "    \"excellent\": 3,\n",
    "    \"good\": 2,\n",
    "    \"fair\": 1,\n",
    "    \"salvage\": 0\n",
    "}\n",
    "\n",
    "# atribuindo os valores numéricos ao dataset\n",
    "car_data['condition'] = car_data['condition'].map(condition_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando features e target\n",
    "features = car_data.drop('price', axis=1)\n",
    "target = car_data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicando One-Hot Encoding nas variáveis categóricas restantes\n",
    "features_encoded = pd.get_dummies(features, columns=['model', 'fuel', 'transmission', 'type', 'paint_color', 'brand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando dados de treino e teste\n",
    "features_train, features_test, target_train, target_test = train_test_split(features_encoded, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37096381187438965"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(features_train, target_train)\n",
    "end = time.time()\n",
    "tempo = end - start\n",
    "tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6463556388680558 0.5734454636073181\n"
     ]
    }
   ],
   "source": [
    "print(model.score(features_train, target_train),\n",
    "model.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6866.667619648236"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = mean_squared_error(target_test, predictions)** 0.5\n",
    "rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vehicles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
