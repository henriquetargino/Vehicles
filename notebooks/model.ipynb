{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bibliotecas\n",
    "import pandas as pd\n",
    "import time\n",
    "# funÃ§Ãµes \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# modelos\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|             | Random Forest(est= 11, depth=27)   | Random Forest(est=100, depth=27)  | LinearRegression(fit_intercept, jobs=-1)   |\n",
    "|-------------|------------|------------|------------|\n",
    "| train_score     | ðŸŸ¨0.9698145941866823    | ðŸŸ©0.975808533590373    | ðŸŸ¥0.720336930225542    |\n",
    "| test_score     | ðŸŸ¨0.8547403645319819    |ðŸŸ©0.8656546507386057    | ðŸŸ¥0.7211501035967206    |\n",
    "| MAE($)  | ðŸŸ¨1872.6269980729571    | ðŸŸ©1785.8674366448959    | ðŸŸ¥2838.1486088502406    |\n",
    "| time(s)     | ðŸŸ¨8.10574460029602    | ðŸŸ¥66.94056940078735    | ðŸŸ©0.4054858684539795    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "legenda: treino, teste, erro, tempo<br><br>\n",
    "n_estimators=11, max_depth=27 -> 0.9557926155884157 0.8334794802644814 3931.966016272742 8.193240880966187<br> <br>\n",
    "n_estimators=100, max_depth=27 -> 0.9650129200912126 0.8408169218841756 3873.6263369273256 79.8025176525116<br>\n",
    "# Linear Regression\n",
    "legenda: treino, teste, erro<br><br>\n",
    "fit_intercept=True, n_jobs=-1 -> 0.6463556388680558 0.5734454636073181 6866.667619648236<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CÃ©lula usada para encontrar os melhores hiperparÃ¢metros da Random Forest\n",
    "\n",
    "```best_error = float('inf')\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "\n",
    "for est in range(10, 101, 5):\n",
    "    for depth in range(20, 31):\n",
    "        model = RandomForestRegressor(random_state=1506, n_estimators=est, max_depth=depth)\n",
    "        model.fit(features_train, target_train)\n",
    "        predictions_test = model.predict(features_test)\n",
    "        error = mean_squared_error(target_test, predictions_test)**0.5\n",
    "        print(f\"ValidaÃ§Ã£o de REQM para n_estimators={est}, depth={depth} Ã© {error}\")\n",
    "        if error < best_error:\n",
    "            best_error = error\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "\n",
    "print(f\"Melhor REQM de teste: {best_error} com n_estimators={best_est} e max_depth={best_depth}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando dataset\n",
    "car_data = pd.read_csv('datasets/car_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retirando colunas que nÃ£o serÃ£o utilizadas\n",
    "car_data = car_data.drop(['date_posted', 'days_listed', 'year_posted', 'car_age'] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar outliers usando IQR\n",
    "Q1 = car_data['price'].quantile(0.25)\n",
    "Q3 = car_data['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Filtrar outliers\n",
    "car_data = car_data[~((car_data['price'] < (Q1 - 1.5 * IQR)) | (car_data['price'] > (Q3 + 1.5 * IQR)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformando a coluna condition em numÃ©rica colocando \"pesos\" para cada condiÃ§Ã£o\n",
    "condition_mapping = {\n",
    "    \"new\": 5,\n",
    "    \"like new\": 4,\n",
    "    \"excellent\": 3,\n",
    "    \"good\": 2,\n",
    "    \"fair\": 1,\n",
    "    \"salvage\": 0\n",
    "}\n",
    "\n",
    "# atribuindo os valores numÃ©ricos ao dataset\n",
    "car_data['condition'] = car_data['condition'].map(condition_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando features e target\n",
    "features = car_data.drop('price', axis=1)\n",
    "target = car_data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicando One-Hot Encoding nas variÃ¡veis categÃ³ricas restantes\n",
    "features_encoded = pd.get_dummies(features, columns=['model', 'fuel', 'transmission', 'type', 'paint_color', 'brand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando dados de treino e teste\n",
    "features_train, features_test, target_train, target_test = train_test_split(features_encoded, target, test_size=0.2, random_state=1506, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=1506, n_estimators=11, max_depth=27, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.704869747161865"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(features_train, target_train)\n",
    "end = time.time()\n",
    "tempo = end - start\n",
    "tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9699817221823089 0.8545331007661833\n"
     ]
    }
   ],
   "source": [
    "print(model.score(features_train, target_train),\n",
    "model.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19900.         28466.61043674  4698.45454545 ...  8359.08431477\n",
      "  5525.14146465 13956.73783287]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(features_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33882    19900\n",
      "14809    34000\n",
      "32496     1800\n",
      "28582     2900\n",
      "7332     25900\n",
      "         ...  \n",
      "36037    12000\n",
      "49324     5200\n",
      "22230     9900\n",
      "49193     4900\n",
      "38880    12500\n",
      "Name: price, Length: 9759, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE: 2913.364558864547 \n",
      " MAE: 1795.9145966752583\n"
     ]
    }
   ],
   "source": [
    "rmse = mean_squared_error(target_test, predictions)**0.5\n",
    "mae = mean_absolute_error(target_test, predictions)\n",
    "print(f' RMSE: {rmse} \\n MAE: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_data.to_csv('model.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model to pickle file\n",
    "with open(\"predict.pkl\", \"wb\") as file: # file is a variable for storing the newly created file, it can be anything.\n",
    "    pickle.dump(model, file) # Dump function is used to write the object into the created file in byte format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O carro custa 19900.0\n"
     ]
    }
   ],
   "source": [
    "# The model has now been deserialized, next is to make use of it as you normally would.\n",
    "prediction = model_pkl.predict(features_test) # Passing in variables for prediction\n",
    "print(\"O carro custa\",prediction[0]) # Printing result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vehicles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
